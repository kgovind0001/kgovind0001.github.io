2:I[3523,["231","static/chunks/231-bd81334f6b279a17.js","147","static/chunks/147-cd109aac514ccfb0.js","107","static/chunks/app/blog/page/%5Bpage%5D/page-d8f7d14300242109.js"],"default"]
45:I[9275,[],""]
47:I[1343,[],""]
48:I[7100,["231","static/chunks/231-bd81334f6b279a17.js","716","static/chunks/716-53788a07dc5c2e2c.js","173","static/chunks/173-0b547d6809efe985.js","185","static/chunks/app/layout-bf5e84be11abd848.js"],"Toaster"]
49:I[231,["231","static/chunks/231-bd81334f6b279a17.js","173","static/chunks/173-0b547d6809efe985.js","797","static/chunks/app/blog/%5B...slug%5D/page-81c19b54ad3d6fee.js"],""]
4a:I[8173,["231","static/chunks/231-bd81334f6b279a17.js","173","static/chunks/173-0b547d6809efe985.js","797","static/chunks/app/blog/%5B...slug%5D/page-81c19b54ad3d6fee.js"],"Image"]
4b:I[9858,["231","static/chunks/231-bd81334f6b279a17.js","716","static/chunks/716-53788a07dc5c2e2c.js","173","static/chunks/173-0b547d6809efe985.js","185","static/chunks/app/layout-bf5e84be11abd848.js"],"Root"]
4c:I[9858,["231","static/chunks/231-bd81334f6b279a17.js","716","static/chunks/716-53788a07dc5c2e2c.js","173","static/chunks/173-0b547d6809efe985.js","185","static/chunks/app/layout-bf5e84be11abd848.js"],"List"]
4d:I[9858,["231","static/chunks/231-bd81334f6b279a17.js","716","static/chunks/716-53788a07dc5c2e2c.js","173","static/chunks/173-0b547d6809efe985.js","185","static/chunks/app/layout-bf5e84be11abd848.js"],"Item"]
4e:I[9858,["231","static/chunks/231-bd81334f6b279a17.js","716","static/chunks/716-53788a07dc5c2e2c.js","173","static/chunks/173-0b547d6809efe985.js","185","static/chunks/app/layout-bf5e84be11abd848.js"],"Link"]
4f:I[9858,["231","static/chunks/231-bd81334f6b279a17.js","716","static/chunks/716-53788a07dc5c2e2c.js","173","static/chunks/173-0b547d6809efe985.js","185","static/chunks/app/layout-bf5e84be11abd848.js"],"Viewport"]
4:["Large Language Models","AI","Machine Learning","LLM","Transformers"]
5:{"text":"16 min read","minutes":15.53,"time":931800,"words":3106}
7:{"value":"Why Consider Building an LLM from Scratch?","url":"#why-consider-building-an-llm-from-scratch-1","depth":2}
8:{"value":"Assessing the Need","url":"#assessing-the-need-1","depth":3}
9:{"value":"The Financial Cost of Building an LLM","url":"#the-financial-cost-of-building-an-llm-1","depth":2}
a:{"value":"Cost Breakdown","url":"#cost-breakdown-1","depth":3}
b:{"value":"Translating Compute Time into Costs","url":"#translating-compute-time-into-costs-1","depth":3}
c:{"value":"The Four Essential Steps in Building an LLM","url":"#the-four-essential-steps-in-building-an-llm-1","depth":2}
d:{"value":"Step 1: Data Curation","url":"#step-1-data-curation-1","depth":3}
e:{"value":"The Scale of Data Required","url":"#the-scale-of-data-required-1","depth":4}
f:{"value":"Sourcing the Data","url":"#sourcing-the-data-1","depth":4}
10:{"value":"Ensuring Data Diversity","url":"#ensuring-data-diversity-1","depth":4}
11:{"value":"Preparing the Data","url":"#preparing-the-data-1","depth":4}
12:{"value":"Step 2: Model Architecture","url":"#step-2-model-architecture-1","depth":3}
13:{"value":"The Transformer Architecture","url":"#the-transformer-architecture-1","depth":4}
14:{"value":"Types of Transformer Architectures","url":"#types-of-transformer-architectures-1","depth":4}
15:{"value":"Design Considerations Beyond Architecture","url":"#design-considerations-beyond-architecture-1","depth":4}
16:{"value":"Step 3: Training at Scale","url":"#step-3-training-at-scale-1","depth":3}
17:{"value":"Key Training Techniques","url":"#key-training-techniques-1","depth":4}
18:{"value":"Ensuring Training Stability","url":"#ensuring-training-stability-1","depth":4}
19:{"value":"Hyperparameter Tuning","url":"#hyperparameter-tuning-1","depth":4}
1a:{"value":"Step 4: Model Evaluation","url":"#step-4-model-evaluation-1","depth":3}
1b:{"value":"Evaluation on Multiple-Choice Tasks","url":"#evaluation-on-multiple-choice-tasks-1","depth":4}
1c:{"value":"Evaluating Open-Ended Tasks","url":"#evaluating-open-ended-tasks-1","depth":4}
1d:{"value":"Final Thoughts: What Comes Next?","url":"#final-thoughts-what-comes-next-1","depth":3}
1e:{"value":"Future Directions","url":"#future-directions-1","depth":4}
1f:{"value":"Conclusion","url":"#conclusion-1","depth":3}
6:["$7","$8","$9","$a","$b","$c","$d","$e","$f","$10","$11","$12","$13","$14","$15","$16","$17","$18","$19","$1a","$1b","$1c","$1d","$1e","$1f"]
20:{"@context":"https://schema.org","@type":"BlogPosting","headline":"Comprehensive Guide to Building Large Language Models from Scratch: Key Considerations and Technical Insights","datePublished":"2024-08-24T00:00:00.000Z","dateModified":"2024-08-24T00:00:00.000Z","description":"Building a large language model (LLM) from scratch involves significant financial and computational resources, requiring extensive data curation, model architecture design, and scalable training processes. This blog explores the complexities and costs of developing LLMs, including key steps like data sourcing, quality filtering, model design choices, and training techniques. While creating an LLM can offer tailored solutions for specific needs, the investment is often substantial. Alternatives like prompt engineering or fine-tuning existing models are more practical for most use cases, providing similar benefits without the high costs of building a model from scratch.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/LLM-model-from-scratch"}
3:{"title":"Comprehensive Guide to Building Large Language Models from Scratch: Key Considerations and Technical Insights","date":"2024-08-24T00:00:00.000Z","tags":"$4","draft":false,"summary":"Building a large language model (LLM) from scratch involves significant financial and computational resources, requiring extensive data curation, model architecture design, and scalable training processes. This blog explores the complexities and costs of developing LLMs, including key steps like data sourcing, quality filtering, model design choices, and training techniques. While creating an LLM can offer tailored solutions for specific needs, the investment is often substantial. Alternatives like prompt engineering or fine-tuning existing models are more practical for most use cases, providing similar benefits without the high costs of building a model from scratch.","type":"Blog","readingTime":"$5","slug":"LLM-model-from-scratch","path":"blog/LLM-model-from-scratch","filePath":"blog/LLM-model-from-scratch.mdx","toc":"$6","structuredData":"$20"}
22:["llama2","colon cancer"]
23:{"text":"11 min read","minutes":10.9,"time":654000,"words":2180}
25:{"value":"Introduction","url":"#introduction","depth":1}
26:{"value":"Solution","url":"#solution","depth":1}
27:{"value":"Step1: Extract information of the blog content.","url":"#step1-extract-information-of-the-blog-content","depth":2}
28:{"value":"Step2: Retrive the most important content from the blog for a query.","url":"#step2-retrive-the-most-important-content-from-the-blog-for-a-query","depth":2}
29:{"value":"Step3: Finetune Llama2 model.","url":"#step3-finetune-llama2-model","depth":2}
2a:{"value":"Conclusion","url":"#conclusion-1","depth":2}
24:["$25","$26","$27","$28","$29","$2a"]
2b:{"@context":"https://schema.org","@type":"BlogPosting","headline":"Predicting accuracy of medical blogs on colon cancer using Llama2","datePublished":"2024-01-12T00:00:00.000Z","dateModified":"2024-01-12T00:00:00.000Z","description":"In the digital age, many blogs provide information on diseases, early signs and symptoms, and treatment methods. However, the accuracy of this information can vary. AI, like Llama2, can be used to analyze these blogs and predict the correctness of the information. By training Llama2 on verified medical data, it can cross-check the information in the blogs, identifying inaccuracies and ensuring the content is reliable. This helps users access accurate health information and make informed decisions.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/medical-blog-ranking-llama2"}
21:{"title":"Predicting accuracy of medical blogs on colon cancer using Llama2","date":"2024-01-12T00:00:00.000Z","tags":"$22","draft":false,"summary":"In the digital age, many blogs provide information on diseases, early signs and symptoms, and treatment methods. However, the accuracy of this information can vary. AI, like Llama2, can be used to analyze these blogs and predict the correctness of the information. By training Llama2 on verified medical data, it can cross-check the information in the blogs, identifying inaccuracies and ensuring the content is reliable. This helps users access accurate health information and make informed decisions.","type":"Blog","readingTime":"$23","slug":"medical-blog-ranking-llama2","path":"blog/medical-blog-ranking-llama2","filePath":"blog/medical-blog-ranking-llama2.mdx","toc":"$24","structuredData":"$2b"}
2d:["Construction","Quantity Takeoff","Yolo","Object Detection"]
2e:{"text":"7 min read","minutes":6.485,"time":389100,"words":1297}
30:{"value":"Problem Statement","url":"#problem-statement-25","depth":2}
31:{"value":"Challenges","url":"#challenges-25","depth":2}
32:{"value":"Classical Approach: Template matching","url":"#classical-approach-template-matching-25","depth":2}
2f:["$30","$31","$32"]
33:{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introduction to Construction Material Quantity Takeoff:- Counting the symbols","datePublished":"2023-09-01T00:00:00.000Z","dateModified":"2023-09-01T00:00:00.000Z","description":"Counting items in a construction plan is an important task where we count the items present in the drawings. In this blog, we introduce the problem statement and the challenges in developing a AI based model which can be used to count the items.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/construction-material-quantity-takeoff-Part1"}
2c:{"title":"Introduction to Construction Material Quantity Takeoff:- Counting the symbols","date":"2023-09-01T00:00:00.000Z","tags":"$2d","draft":false,"summary":"Counting items in a construction plan is an important task where we count the items present in the drawings. In this blog, we introduce the problem statement and the challenges in developing a AI based model which can be used to count the items.","type":"Blog","readingTime":"$2e","slug":"construction-material-quantity-takeoff-Part1","path":"blog/construction-material-quantity-takeoff-Part1","filePath":"blog/construction-material-quantity-takeoff-Part1.mdx","toc":"$2f","structuredData":"$33"}
35:["Construction","Quantity Takeoff","Yolo","Object Detection","dinoV2","Faiss","vectordatabase"]
36:{"text":"1 min read","minutes":0.17,"time":10200,"words":34}
37:[]
38:{"@context":"https://schema.org","@type":"BlogPosting","headline":"Construction Material Quantity Takeoff Using AI:- Counting the symbols","datePublished":"2023-09-01T00:00:00.000Z","dateModified":"2023-09-01T00:00:00.000Z","description":"A two step AI based solution is proposed to count symbols in a plan for material quantity takeoff in construction. The first step is to perform object detection where the objective is to predict all the symbols present in the drawing. Once we have all the symbols, then we can perform indexing of symbols from the legend using dinoV2 model and Faiss vectordatabase.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/construction-material-quantity-takeoff-Part2"}
34:{"title":"Construction Material Quantity Takeoff Using AI:- Counting the symbols","date":"2023-09-01T00:00:00.000Z","tags":"$35","draft":false,"summary":"A two step AI based solution is proposed to count symbols in a plan for material quantity takeoff in construction. The first step is to perform object detection where the objective is to predict all the symbols present in the drawing. Once we have all the symbols, then we can perform indexing of symbols from the legend using dinoV2 model and Faiss vectordatabase.","type":"Blog","readingTime":"$36","slug":"construction-material-quantity-takeoff-Part2","path":"blog/construction-material-quantity-takeoff-Part2","filePath":"blog/construction-material-quantity-takeoff-Part2.mdx","toc":"$37","structuredData":"$38"}
3a:["dreambooth","stable diffusion","dislocation","synthetic data"]
3b:{"text":"8 min read","minutes":7.165,"time":429900,"words":1433}
3d:{"value":"DreamBooth:","url":"#dreambooth","depth":2}
3e:{"value":"Differences between DreamBooth and Standard Fine-Tuning of Stable Diffusion","url":"#differences-between-dreambooth-and-standard-fine-tuning-of-stable-diffusion","depth":2}
3f:{"value":"Motivation","url":"#motivation","depth":2}
40:{"value":"Finetune","url":"#finetune","depth":2}
41:{"value":"Results","url":"#results","depth":2}
42:{"value":"Limitations","url":"#limitations","depth":3}
43:{"value":"Conclusion","url":"#conclusion","depth":2}
3c:["$3d","$3e","$3f","$40","$41","$42","$43"]
44:{"@context":"https://schema.org","@type":"BlogPosting","headline":"Generate synthetic images of dislocation microstructure using Dreambooth","datePublished":"2023-08-20T00:00:00.000Z","dateModified":"2023-08-20T00:00:00.000Z","description":"Finetuning dreambooth provides a unique way to generate synthetic images using just a couple of images. DreamBooth is a technique for personalizing text-to-image models such as Stable Diffusion by fine-tuning them with a small number of images (usually 3 to 5) of a specific subject. This method allows the model to generate images that incorporate the characteristics of the subject in new, synthesized scenes.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/dreambooth-dislocations-synthetic-images"}
39:{"title":"Generate synthetic images of dislocation microstructure using Dreambooth","date":"2023-08-20T00:00:00.000Z","tags":"$3a","draft":false,"summary":"Finetuning dreambooth provides a unique way to generate synthetic images using just a couple of images. DreamBooth is a technique for personalizing text-to-image models such as Stable Diffusion by fine-tuning them with a small number of images (usually 3 to 5) of a specific subject. This method allows the model to generate images that incorporate the characteristics of the subject in new, synthesized scenes.","type":"Blog","readingTime":"$3b","slug":"dreambooth-dislocations-synthetic-images","path":"blog/dreambooth-dislocations-synthetic-images","filePath":"blog/dreambooth-dislocations-synthetic-images.mdx","toc":"$3c","structuredData":"$44"}
46:["page","1","d"]
0:["zhOrSL33bo2OZH9DMmQ6M",[[["",{"children":["blog",{"children":["page",{"children":[["page","1","d"],{"children":["__PAGE__?{\"page\":\"1\"}",{}]}]}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":["page",{"children":[["page","1","d"],{"children":["__PAGE__",{},[["$L1",["$","$L2",null,{"posts":[{"title":"Comprehensive Guide to Building Large Language Models from Scratch: Key Considerations and Technical Insights","date":"2024-08-24T00:00:00.000Z","tags":["Large Language Models","AI","Machine Learning","LLM","Transformers"],"draft":false,"summary":"Building a large language model (LLM) from scratch involves significant financial and computational resources, requiring extensive data curation, model architecture design, and scalable training processes. This blog explores the complexities and costs of developing LLMs, including key steps like data sourcing, quality filtering, model design choices, and training techniques. While creating an LLM can offer tailored solutions for specific needs, the investment is often substantial. Alternatives like prompt engineering or fine-tuning existing models are more practical for most use cases, providing similar benefits without the high costs of building a model from scratch.","type":"Blog","readingTime":{"text":"16 min read","minutes":15.53,"time":931800,"words":3106},"slug":"LLM-model-from-scratch","path":"blog/LLM-model-from-scratch","filePath":"blog/LLM-model-from-scratch.mdx","toc":[{"value":"Why Consider Building an LLM from Scratch?","url":"#why-consider-building-an-llm-from-scratch-1","depth":2},{"value":"Assessing the Need","url":"#assessing-the-need-1","depth":3},{"value":"The Financial Cost of Building an LLM","url":"#the-financial-cost-of-building-an-llm-1","depth":2},{"value":"Cost Breakdown","url":"#cost-breakdown-1","depth":3},{"value":"Translating Compute Time into Costs","url":"#translating-compute-time-into-costs-1","depth":3},{"value":"The Four Essential Steps in Building an LLM","url":"#the-four-essential-steps-in-building-an-llm-1","depth":2},{"value":"Step 1: Data Curation","url":"#step-1-data-curation-1","depth":3},{"value":"The Scale of Data Required","url":"#the-scale-of-data-required-1","depth":4},{"value":"Sourcing the Data","url":"#sourcing-the-data-1","depth":4},{"value":"Ensuring Data Diversity","url":"#ensuring-data-diversity-1","depth":4},{"value":"Preparing the Data","url":"#preparing-the-data-1","depth":4},{"value":"Step 2: Model Architecture","url":"#step-2-model-architecture-1","depth":3},{"value":"The Transformer Architecture","url":"#the-transformer-architecture-1","depth":4},{"value":"Types of Transformer Architectures","url":"#types-of-transformer-architectures-1","depth":4},{"value":"Design Considerations Beyond Architecture","url":"#design-considerations-beyond-architecture-1","depth":4},{"value":"Step 3: Training at Scale","url":"#step-3-training-at-scale-1","depth":3},{"value":"Key Training Techniques","url":"#key-training-techniques-1","depth":4},{"value":"Ensuring Training Stability","url":"#ensuring-training-stability-1","depth":4},{"value":"Hyperparameter Tuning","url":"#hyperparameter-tuning-1","depth":4},{"value":"Step 4: Model Evaluation","url":"#step-4-model-evaluation-1","depth":3},{"value":"Evaluation on Multiple-Choice Tasks","url":"#evaluation-on-multiple-choice-tasks-1","depth":4},{"value":"Evaluating Open-Ended Tasks","url":"#evaluating-open-ended-tasks-1","depth":4},{"value":"Final Thoughts: What Comes Next?","url":"#final-thoughts-what-comes-next-1","depth":3},{"value":"Future Directions","url":"#future-directions-1","depth":4},{"value":"Conclusion","url":"#conclusion-1","depth":3}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Comprehensive Guide to Building Large Language Models from Scratch: Key Considerations and Technical Insights","datePublished":"2024-08-24T00:00:00.000Z","dateModified":"2024-08-24T00:00:00.000Z","description":"Building a large language model (LLM) from scratch involves significant financial and computational resources, requiring extensive data curation, model architecture design, and scalable training processes. This blog explores the complexities and costs of developing LLMs, including key steps like data sourcing, quality filtering, model design choices, and training techniques. While creating an LLM can offer tailored solutions for specific needs, the investment is often substantial. Alternatives like prompt engineering or fine-tuning existing models are more practical for most use cases, providing similar benefits without the high costs of building a model from scratch.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/LLM-model-from-scratch"}},{"title":"Predicting accuracy of medical blogs on colon cancer using Llama2","date":"2024-01-12T00:00:00.000Z","tags":["llama2","colon cancer"],"draft":false,"summary":"In the digital age, many blogs provide information on diseases, early signs and symptoms, and treatment methods. However, the accuracy of this information can vary. AI, like Llama2, can be used to analyze these blogs and predict the correctness of the information. By training Llama2 on verified medical data, it can cross-check the information in the blogs, identifying inaccuracies and ensuring the content is reliable. This helps users access accurate health information and make informed decisions.","type":"Blog","readingTime":{"text":"11 min read","minutes":10.9,"time":654000,"words":2180},"slug":"medical-blog-ranking-llama2","path":"blog/medical-blog-ranking-llama2","filePath":"blog/medical-blog-ranking-llama2.mdx","toc":[{"value":"Introduction","url":"#introduction","depth":1},{"value":"Solution","url":"#solution","depth":1},{"value":"Step1: Extract information of the blog content.","url":"#step1-extract-information-of-the-blog-content","depth":2},{"value":"Step2: Retrive the most important content from the blog for a query.","url":"#step2-retrive-the-most-important-content-from-the-blog-for-a-query","depth":2},{"value":"Step3: Finetune Llama2 model.","url":"#step3-finetune-llama2-model","depth":2},{"value":"Conclusion","url":"#conclusion-1","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Predicting accuracy of medical blogs on colon cancer using Llama2","datePublished":"2024-01-12T00:00:00.000Z","dateModified":"2024-01-12T00:00:00.000Z","description":"In the digital age, many blogs provide information on diseases, early signs and symptoms, and treatment methods. However, the accuracy of this information can vary. AI, like Llama2, can be used to analyze these blogs and predict the correctness of the information. By training Llama2 on verified medical data, it can cross-check the information in the blogs, identifying inaccuracies and ensuring the content is reliable. This helps users access accurate health information and make informed decisions.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/medical-blog-ranking-llama2"}},{"title":"Introduction to Construction Material Quantity Takeoff:- Counting the symbols","date":"2023-09-01T00:00:00.000Z","tags":["Construction","Quantity Takeoff","Yolo","Object Detection"],"draft":false,"summary":"Counting items in a construction plan is an important task where we count the items present in the drawings. In this blog, we introduce the problem statement and the challenges in developing a AI based model which can be used to count the items.","type":"Blog","readingTime":{"text":"7 min read","minutes":6.485,"time":389100,"words":1297},"slug":"construction-material-quantity-takeoff-Part1","path":"blog/construction-material-quantity-takeoff-Part1","filePath":"blog/construction-material-quantity-takeoff-Part1.mdx","toc":[{"value":"Problem Statement","url":"#problem-statement-25","depth":2},{"value":"Challenges","url":"#challenges-25","depth":2},{"value":"Classical Approach: Template matching","url":"#classical-approach-template-matching-25","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Introduction to Construction Material Quantity Takeoff:- Counting the symbols","datePublished":"2023-09-01T00:00:00.000Z","dateModified":"2023-09-01T00:00:00.000Z","description":"Counting items in a construction plan is an important task where we count the items present in the drawings. In this blog, we introduce the problem statement and the challenges in developing a AI based model which can be used to count the items.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/construction-material-quantity-takeoff-Part1"}},{"title":"Construction Material Quantity Takeoff Using AI:- Counting the symbols","date":"2023-09-01T00:00:00.000Z","tags":["Construction","Quantity Takeoff","Yolo","Object Detection","dinoV2","Faiss","vectordatabase"],"draft":false,"summary":"A two step AI based solution is proposed to count symbols in a plan for material quantity takeoff in construction. The first step is to perform object detection where the objective is to predict all the symbols present in the drawing. Once we have all the symbols, then we can perform indexing of symbols from the legend using dinoV2 model and Faiss vectordatabase.","type":"Blog","readingTime":{"text":"1 min read","minutes":0.17,"time":10200,"words":34},"slug":"construction-material-quantity-takeoff-Part2","path":"blog/construction-material-quantity-takeoff-Part2","filePath":"blog/construction-material-quantity-takeoff-Part2.mdx","toc":[],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Construction Material Quantity Takeoff Using AI:- Counting the symbols","datePublished":"2023-09-01T00:00:00.000Z","dateModified":"2023-09-01T00:00:00.000Z","description":"A two step AI based solution is proposed to count symbols in a plan for material quantity takeoff in construction. The first step is to perform object detection where the objective is to predict all the symbols present in the drawing. Once we have all the symbols, then we can perform indexing of symbols from the legend using dinoV2 model and Faiss vectordatabase.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/construction-material-quantity-takeoff-Part2"}},{"title":"Generate synthetic images of dislocation microstructure using Dreambooth","date":"2023-08-20T00:00:00.000Z","tags":["dreambooth","stable diffusion","dislocation","synthetic data"],"draft":false,"summary":"Finetuning dreambooth provides a unique way to generate synthetic images using just a couple of images. DreamBooth is a technique for personalizing text-to-image models such as Stable Diffusion by fine-tuning them with a small number of images (usually 3 to 5) of a specific subject. This method allows the model to generate images that incorporate the characteristics of the subject in new, synthesized scenes.","type":"Blog","readingTime":{"text":"8 min read","minutes":7.165,"time":429900,"words":1433},"slug":"dreambooth-dislocations-synthetic-images","path":"blog/dreambooth-dislocations-synthetic-images","filePath":"blog/dreambooth-dislocations-synthetic-images.mdx","toc":[{"value":"DreamBooth:","url":"#dreambooth","depth":2},{"value":"Differences between DreamBooth and Standard Fine-Tuning of Stable Diffusion","url":"#differences-between-dreambooth-and-standard-fine-tuning-of-stable-diffusion","depth":2},{"value":"Motivation","url":"#motivation","depth":2},{"value":"Finetune","url":"#finetune","depth":2},{"value":"Results","url":"#results","depth":2},{"value":"Limitations","url":"#limitations","depth":3},{"value":"Conclusion","url":"#conclusion","depth":2}],"structuredData":{"@context":"https://schema.org","@type":"BlogPosting","headline":"Generate synthetic images of dislocation microstructure using Dreambooth","datePublished":"2023-08-20T00:00:00.000Z","dateModified":"2023-08-20T00:00:00.000Z","description":"Finetuning dreambooth provides a unique way to generate synthetic images using just a couple of images. DreamBooth is a technique for personalizing text-to-image models such as Stable Diffusion by fine-tuning them with a small number of images (usually 3 to 5) of a specific subject. This method allows the model to generate images that incorporate the characteristics of the subject in new, synthesized scenes.","image":"/static/images/twitter-card.png","url":"https://mlwithkishan.com/blog/dreambooth-dislocations-synthetic-images"}}],"initialDisplayPosts":["$3","$21","$2c","$34","$39"],"pagination":{"currentPage":1,"totalPages":1},"title":"All Posts"}]],null],null]},["$","$L45",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","page","children","$46","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L47",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L45",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","page","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L47",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},["$","$L45",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L47",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"en","children":[null,["$","body",null,{"className":"flex flex-col min-h-screen","children":[["$","$L48",null,{}],["$","header",null,{"className":"bg-black shadow-lg py-2","children":["$","div",null,{"className":"container mx-auto flex justify-between items-center px-2","children":[["$","$L49",null,{"href":"/","passHref":true,"children":["$","$L4a",null,{"src":"/logo.png","alt":"Logo","width":64,"height":64,"className":"rounded-full shadow-md"}]}],["$","$L4b",null,{"className":"relative z-10 flex max-w-max flex-1 items-center justify-center","children":[["$","$L4c",null,{"className":"group flex flex-1 list-none items-center justify-center space-x-1","children":[["$","$L4d",null,{"children":["$","$L49",null,{"href":"/blog","legacyBehavior":true,"passHref":true,"children":["$","$L4e",null,{"className":"group inline-flex h-10 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground focus:outline-none disabled:pointer-events-none disabled:opacity-50 data-[active]:bg-accent/50 data-[state=open]:bg-accent/50","style":{"backgroundColor":"black","color":"white","fontSize":"24px"},"children":"Blog"}]}]}],["$","$L4d",null,{"children":["$","$L49",null,{"href":"/portfolio","legacyBehavior":true,"passHref":true,"children":["$","$L4e",null,{"className":"group inline-flex h-10 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground focus:outline-none disabled:pointer-events-none disabled:opacity-50 data-[active]:bg-accent/50 data-[state=open]:bg-accent/50","style":{"backgroundColor":"black","color":"white","fontSize":"24px"},"children":"Portfolio"}]}]}],["$","$L4d",null,{"children":["$","$L49",null,{"href":"/apps","legacyBehavior":true,"passHref":true,"children":["$","$L4e",null,{"className":"group inline-flex h-10 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground focus:outline-none disabled:pointer-events-none disabled:opacity-50 data-[active]:bg-accent/50 data-[state=open]:bg-accent/50","style":{"backgroundColor":"black","color":"white","fontSize":"24px"},"children":"Apps"}]}]}],["$","$L4d",null,{"children":["$","$L49",null,{"href":"/contact","legacyBehavior":true,"passHref":true,"children":["$","$L4e",null,{"className":"group inline-flex h-10 w-max items-center justify-center rounded-md bg-background px-4 py-2 text-sm font-medium transition-colors hover:bg-accent hover:text-accent-foreground focus:bg-accent focus:text-accent-foreground focus:outline-none disabled:pointer-events-none disabled:opacity-50 data-[active]:bg-accent/50 data-[state=open]:bg-accent/50","style":{"backgroundColor":"black","color":"white","fontSize":"24px"},"children":"Contact"}]}]}]]}],["$","div",null,{"className":"absolute left-0 top-full flex justify-center","children":["$","$L4f",null,{"className":"origin-top-center relative mt-1.5 h-[var(--radix-navigation-menu-viewport-height)] w-full overflow-hidden rounded-md border bg-popover text-popover-foreground shadow-lg data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-90 md:w-[var(--radix-navigation-menu-viewport-width)]"}]}]]}]]}]}],["$","main",null,{"className":"container mx-auto px-4 py-6 flex-grow bg-gray-100","children":["$","div",null,{"className":"rounded-lg border bg-card text-card-foreground shadow-sm max-w-8xl mx-auto p-6 bg-white shadow-lg rounded-xl border border-gray-200 mt-8","children":["$","$L45",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L47",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":["$","div",null,{"className":"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6","children":[["$","div",null,{"className":"space-x-2 pb-8 pt-6 md:space-y-5","children":["$","h1",null,{"className":"text-6xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 md:border-r-2 md:px-6 md:text-8xl md:leading-14","children":"404"}]}],["$","div",null,{"className":"max-w-md","children":[["$","p",null,{"className":"mb-4 text-xl font-bold leading-normal md:text-2xl","children":"Sorry we couldn't find this page."}],["$","p",null,{"className":"mb-8","children":"But dont worry, you can find plenty of other things on our homepage."}],["$","$L49",null,{"className":"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm font-medium leading-5 text-white shadow transition-colors duration-150 hover:bg-blue-700 focus:outline-none dark:hover:bg-blue-500","href":"/","children":"Back to homepage"}]]}]]}],"notFoundStyles":[],"styles":null}]}]}],["$","footer",null,{"className":"bg-white shadow-md py-4 mt-auto","children":["$","div",null,{"className":"container mx-auto px-6","children":[["$","div",null,{"className":"flex justify-center items-center space-x-4 mb-4","children":[["$","a",null,{"href":"https://scholar.google.com/citations?user=8nRszxkAAAAJ&hl","target":"_blank","rel":"noopener noreferrer","className":"text-gray-700 hover:text-gray-900","aria-label":"Google Scholar","children":["$","$L4a",null,{"src":"/static/images/google-scholar.svg","alt":"Google Scholar","width":32,"height":32,"className":"","loading":"lazy"}]}],["$","a",null,{"href":"https://www.linkedin.com/in/kishan-govind-771a3b65/","target":"_blank","rel":"noopener noreferrer","className":"text-gray-700 hover:text-gray-900","aria-label":"LinkedIn","children":["$","$L4a",null,{"src":"/static/images/linkedin.svg","alt":"LinkedIn","width":32,"height":32,"className":"","loading":"lazy"}]}],["$","a",null,{"href":"https://github.com/kgovind0001","target":"_blank","rel":"noopener noreferrer","className":"text-gray-700 hover:text-gray-900","aria-label":"GitHub","children":["$","$L4a",null,{"src":"/static/images/github.svg","alt":"GitHub","width":32,"height":32,"className":"","loading":"lazy"}]}]]}],["$","p",null,{"className":"text-center text-gray-700","children":"Blog on ML, AI & other acronyms. Â© 2020 - 2024 Kishan Govind"}]]}]}]]}]]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/cd54d9bab3c4d190.css","precedence":"next","crossOrigin":"$undefined"}]],"$L50"]]]]
50:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","meta","2",{"name":"next-size-adjust"}]]
1:null
